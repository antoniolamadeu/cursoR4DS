---
title: "Aula 2"
author: "Curso-R"
date: "25 de outubro de 2017"
output: html_document
---

## Recapitulação da Aula 1

- pipe
- RMarkdown
- Importação dos dados
- Diagnóstico inicial
- Limpeza dos dados
- Descritivas: tabelas de contingência e gráficos
- Preparação da variável resposta
- regex, gather/spread, dplyr, tidyr, stringr, lubridate.

```{r, echo=FALSE}
knitr::include_graphics("ciclo_aula1.png")
```


## Exercícios da Aula 1. Dúvidas?

```{r}
library(tidyverse)
d_infos <- readr::read_rds("data/d_infos_tratado.rds")
```

1) Identifique os relatores com mais decisoes "Provido" em quantidade e percentualmente.

```{r}
d_infos %>%
  group_by(relator) %>%
  summarise(n = n(),
            n_provido = sum(decisao_binaria == "Provido"),
            p_provido = n_provido / n) %>%
  filter(n_provido == max(n_provido) | p_provido == max(p_provido)) %>%
  # filter(n > 5) %>%
  arrange(desc(n_provido), desc(p_provido))
```

2) Dependendo do assunto do processo a duração é diferente? Compare apenas entre os assuntos intermediários que mais acontecem.

```{r}
library(forcats)
d_infos %>%
  mutate(duracao = as.numeric(duracao),
         assunto_intermediario = assunto_intermediario %>% 
           str_wrap(12) %>% 
           fct_reorder(duracao) %>% 
           fct_lump(5, other_level = "Outro")) %>%
  # filter(duracao < 4000) %>%
  ggplot() +
  geom_boxplot(aes(x = assunto_intermediario, y = duracao)) +
  coord_flip()
```

3) Qual é o Foro com maior número de processos? 

```{r}
d_infos %>% 
  separate(origem, c("comarca", "foro", "vara"), sep = " / ") %>% 
  count(comarca, foro, sort = TRUE)
```

4) Existe diferença no resultado do processo dependendo da classe? Faça um gráfico p/ apresentar os resultados.
5) Em geral os relatores se apresentam sempre na mesma Vara? Faça um gráfico p/ apresentar os resultados.
6) Existe diferença na duração dos processos entre as Comarcas? Faça um gráfico p/ apresentar os resultados.
7) Qual é o primeiro nome mais comum entre os relatores e revisores? Faça um gráfico p/ apresentar os resultados.
8) Qual é o número médio de palavras do texto da decisão por assunto? Faça um gráfico p/ apresentar os resultados.
9) Existem pares de revisores e relatores que analisaram mais de 10 processos juntos?
10) Quantos assuntos distintos são julgados em cada vara? Faça um gráfico p/ apresentar os resultados.

<!-- ----------------------------------------------------------------------- -->

## Aula 2

```{r, echo=FALSE}
knitr::include_graphics("ciclo_aula2.png")
```

- Pré-processamentos
- criação de variáveis
- bag of words


<!-- 1h00' OK -->
- Setup
- Exercicios anteriores
- Revisao (principalmente ggplot2)

<!-- 1h30' OK -->
- Conceitos
- erros de ajuste vs. erros de predição
- Sobreajuste (Overfiting)

<!-- 3h00' -->
- regressão logística (nao esquecer de falar de formula)
    - ajustar um modelo
    - mude a formula
- árvore de decisão
    - ajustar um modelo
    - plotar a arvore
- matriz de confusão, tpr, fpr
    - fazer a tabela de acertos na base de teste
- curva ROC
    - ajustar uma curva ROC
    - comparar acerto dos modelos usando vários critérios (AUC, acerto)

<!-- ----------------------------------------------------------------------- -->

<!-- 5h00' FALTA bagging, rf xgboost -->
- Validação cruzada (cross-validation)
- regularização (LASSO)
- bagging (conceituação teórica)
- LASSO
    - ajustar um lasso
- random forest
    - ajustar um rf
- xgboost
    - ajustar um xgboost

<!-- 6h00' OK -->
- communicate
    - flexdashboards
    - API
        - captcha

<!-- ----------------------------------------------------------------------- -->


```{r}
d_infos %>% 
  count(resultado, decisao_binaria)
```


### Arrumação da base


```{r}
# processos <- readRDS("../Aula 1/data/processos_pra_pegar.rds")
# RAW
d_cjsg <- read_rds("data/d_cjsg.rds") %>% 
  mutate(n_processo = str_replace_all(n_processo, "[^0-9]", ""))
dataset <- read_rds("../Aula 1/data/d_cposg.rds")

partes <- dataset %>% 
  select(id, parts) %>% 
  unnest(parts) %>% 
  filter(part %in% c("Apelante", "Apelado"), role != "Advogado") %>% 
  # juntar casos com múltiplas partes
  group_by(id, id1, part) %>% 
  summarise(name = paste(name, collapse = "\n")) %>% 
  ungroup() %>%
  # classificacao de tipo de pessoa
  mutate(tipo_part = case_when(
    str_detect(name, "Minist|Justi") ~ "MP",
    TRUE ~ "pessoa"
  )) %>% 
  # em alguns casos, existem pessoas no polo passivo e ativo. 
  # vamos considerar só um (simplificacao)
  distinct(id, part, tipo_part) %>% 
  spread(part, tipo_part) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(apelante)) %>% 
  select(id, autor = apelante)

informacoes <- dataset %>% 
  semi_join(partes, "id") %>% 
  select(id, data) %>% 
  unnest(data) %>% 
  spread(data, value) %>% 
  janitor::clean_names() %>% 
  abjutils::rm_accent_from_names() %>% 
  filter(str_detect(distribuicao, "de Direito Criminal|Extraord")) %>% 
  separate(origem, c("comarca", "foro", "vara"), 
           sep = " / ", extra = "merge", fill = "right") %>% 
  mutate(foro_origem = fct_lump(foro, 10)) %>% 
  separate(assunto, c("assunto_geral", "assunto_intermediario", "assunto"), 
    sep = "-", extra = 'merge', fill = 'right'
  ) %>% 
  mutate_at(vars(assunto, assunto_intermediario), funs(str_trim)) %>% 
  mutate(tipo_camara = if_else(str_detect(distribuicao, "Extra"), 
                               "Extraordinaria", "Ordinaria")) %>% 
  mutate(num_camara = str_extract(distribuicao, "^[0-9]+"),
         num_camara = str_pad(num_camara, 2, "0", side = "left")) %>% 
  select(id, assunto_intermediario, assunto, 
         num_camara, tipo_camara, foro_origem, relator)

tempos <- dataset %>% 
  semi_join(partes, "id") %>% 
  select(id, movs) %>% 
  unnest(movs) %>% 
  filter(movement < Sys.Date(), movement > as.Date("2000-01-01")) %>% 
  group_by(id) %>% 
  summarise(n_movs = n(),
            tempo = as.numeric(max(movement) - min(movement)))

  
# Varias regex
re_vu <- regex("unanim|V\\.? ?U\\.?", ignore_case = TRUE)
re_negaram <- regex("negaram|improc|improv|mantiv|não prov", ignore_case = TRUE)
re_parcial <- regex("parcial|em parte", ignore_case = TRUE)
re_extin <- regex("extin|prejud", ignore_case = TRUE)
re_nulo <- regex("anul|nul[ia]|dilig|conhec", ignore_case = TRUE)
re_deram <- regex("deram|provim|acolher", ignore_case = TRUE)

# todos os tipos de outros
outros <- c("Extinto", "Anul., Dilig., Nao Conhec.", "Outros")

decisoes <- dataset %>% 
  select(id, decisions) %>% 
  unnest(decisions) %>% 
  inner_join(partes, "id") %>% 
  arrange(desc(date)) %>% 
  filter(!is.na(decision)) %>% 
  distinct(id, .keep_all = TRUE) %>% 
  mutate(
    unanime = if_else(str_detect(decision, re_vu), "Unanime", "Nao Unanime"),
    decisao = case_when(
      str_detect(decision, re_negaram) & autor == "MP" ~ "Favoravel",
      str_detect(decision, re_negaram) & autor == "pessoa" ~ "Desfavoravel",
      str_detect(decision, re_parcial) ~ "Parcialmente",
      str_detect(decision, re_extin) ~ "Extinto",
      str_detect(decision, re_nulo) ~ "Anul., Dilig., Nao Conhec.",
      str_detect(decision, re_deram) & autor == "MP" ~ "Desfavoravel",
      str_detect(decision, re_deram) & autor == "pessoa" ~ "Favoravel",
      TRUE ~ "Outros"
    ),
    decisao_bin = case_when(
      decisao %in% c("Favoravel", "Parcialmente") ~ "Favoravel",
      (decisao %in% outros & autor == "MP") ~ "Favoravel",
      (decisao %in% outros & autor == "pessoa") ~ "Desfavoravel",
      TRUE ~ "Desfavoravel"
    )
  ) %>% 
  select(id, decisao_bin, decisao, autor, unanime)


d_final <- decisoes %>% 
  inner_join(tempos, "id") %>% 
  inner_join(informacoes, "id") %>% 
  distinct(id, .keep_all = TRUE) %>% 
  mutate(decisao_bin = factor(decisao_bin))
```


```{r}
set.seed(10)
treino <- d_final %>% 
  sample_n(18000)
teste <- d_final %>% 
  anti_join(treino, "id")


m <- glm(decisao_bin ~ autor + n_movs + tempo + assunto + 
           num_camara * tipo_camara + foro_origem, 
         data = teste, family = binomial())

m %>% 
  broom::augment(newdata = teste, type.predict = "response") %>% 
  filter(!is.na(.fitted)) %>% 
  mutate(res = if_else(.fitted > .5, "Favoravel", "Desfavoravel")) %>% 
  summarise(prop = sum(res == decisao_bin) / n()) %>% 
  with(prop)

teste %>% 
  count(decisao_bin) %>% 
  mutate(prop = n/sum(n))

```


```{r}
dataset <- readr::read_rds("data/d_cposg.rds")

d_infos <- informacoes %>% 
  inner_join(decisoes) %>% 
  #inner_join(movs) %>% 
  filter(area == "Criminal",
         id %in% processos,
         !distribuicao %in% c("5ª Câmara de Direito Criminal D", "Órgão Especial"),
         situacao %in% c("Encerrado", "Julgado", "Transitado")
         # Tiramos o "administrativamente" porque são casos em que não há julgamento do mérito
         ) %>% 
  select(-x, -outros_numeros, -numeros_de_origem, -processo, -ultima_carga, -volume_apenso) %>% 
  rename(data_ultima_decisao = date,
         decisao = decision) %>% 
  mutate(data_ultima_decisao = format(data_ultima_decisao, "%d/%m/%Y")
         #data_dist = format(data_dist, "%d/%m/%Y")
  )

saveRDS(d_infos, 'data/infos_processos.rds')
saveRDS(movs,  'data/movs_processos.rds')
```







<!-- ----------------------------------------------------------------------- -->


## Regressão Logística

### dados

```{r}
# pacotes
library(glmnet)
library(glmnetUtils)
library(tidyverse)
```

```{r}
# dados simulados
set.seed(19880923)
n <- 10000
df <- rnorm(30 * n) %>%
  matrix(nrow = n) %>%
  as.data.frame() %>%
  mutate(y = rbinom(n, 1, prob = 1/(1 + exp(-1 * (-1 + 0.5 * V1 + 0.5 * V2 + 0.5 * V3)))),
         particao = ifelse(runif(n()) > 0.3, "treino", "teste"))
```


### glm com LASSO - Ajuste do modelo logístico penalizado no R

```{r}
modelo_com_lasso <- glmnetUtils::cv.glmnet(y ~ .,
                                           data = df %>% filter(particao == "treino") %>% select(-particao),
                                           family = "binomial",
                                           alpha = 1)
plot(modelo_com_lasso)
```

```{r}
# lambda escolhido
modelo_com_lasso$lambda.1se

# coeficientes
coef(modelo_com_lasso, s = "lambda.1se")
```


## O que é um modelo bom?

```{r}
# plugando o score na base
df <- df %>%
  mutate(predito = as.vector(predict(modelo_com_lasso, newdata = ., type = "response")))
```

classificar usando a média da base

```{r}
# tabela de confundimento
df <- df %>%
  mutate(classe_predita = if_else(predito > mean(y), 1, 0))
tab_de_conf <- table(df$y, df$classe_predita)
tab_de_conf
```

```{r}
# acurácia
acc <- sum(diag(tab_de_conf))/sum(tab_de_conf)
acc
```


Mas e se fizessemos classe predita = 1 pra todo mundo?

```{r}
# tabela de confundimento
df <- df %>%
  mutate(um_pra_todo_mundo = 1)

tab_de_conf_degenerada <- table(df$y, df$um_pra_todo_mundo)
tab_de_conf_degenerada
```

```{r}
# acurácia
acc <- sum(diag(tab_de_conf_degenerada)) / sum(tab_de_conf_degenerada)
acc
```


## Alternativas para medir desempenho do modelo logístico

- KS
- Curva ROC / AUC
- (um monte de outras, mas menos comum)

### KS

Definição: maior distância entre a FDA dos scores dos 1's e a FDA dos scores dos 0's

```{r}
ggplot(df) +
  stat_ecdf(aes(x = predito, colour = factor(y)))
```

Estatística KS

```{r}
# modelo
with(df, ks.test(predito[y == 1], predito[y == 0]))$statistic %>% round(2)

# UM pra todo mundo
with(df, ks.test(um_pra_todo_mundo[y == 1], um_pra_todo_mundo[y == 0]))$statistic %>% round(2)
```


## Área sobre a curva ROC

```{r}
knitr::include_graphics("confusion_matrix.png")
```

Atenção! Uma pequena confusão:

- Sensibilidade é TRUE POSITIVE RATE
- Especificidade é 1 - FALSE POSITIVE RATE

```{r}
tpr <- function(real, predito, corte) {
  sum(predito >= corte & real == 1) / sum(real == 1)
}

fpr <- function(real, predito, corte) {
  sum(predito >= corte & real == 0) / sum(real == 0)
}
with(df, tpr(y, predito, mean(y)))
```

Curva ROC

um monte de "matriz de confundimento". No exemplo, 100 delas.

```{r}
cortes <- seq(0, 1, l = 100)
TPR_modelo <- sapply(cortes, function(x) tpr(df$y, df$predito, x))
FPR_modelo <- sapply(cortes, function(x) fpr(df$y, df$predito, x))

TPR_aleatorio <- sapply(cortes, function(x) tpr(df$y, rep(1, length(df$y)), x))
FPR_aleatorio <- sapply(cortes, function(x) fpr(df$y, rep(1, length(df$y)), x))

data.frame(
  tipo = rep(c("modelo", "aleatorio"), each = length(cortes)),
  TPR = c(TPR_modelo, TPR_aleatorio),
  FPR = c(FPR_modelo, FPR_aleatorio)
) %>%
  ggplot(aes(x = FPR, y = TPR, color = tipo)) +
  geom_line() +
  geom_abline(slope = 1, intercept = 0, colour = "red")
```

### AUC

AUC é a área sob a curva ROC. Vai de 0.5 a 1.

```{r}
df %>%
  summarise(auc_modelo = Metrics::auc(y, predito),
            auc_aleatorio = Metrics::auc(y, runif(n())))
```
